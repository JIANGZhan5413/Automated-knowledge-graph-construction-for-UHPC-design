{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b559fec1-3cc3-47a5-a585-96f4b233763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import docx\n",
    "from docx import Document\n",
    "from typing import List, Dict, Any\n",
    "import time\n",
    "\n",
    "# Change 1: Use Deepseek API Key\n",
    "if \"DEEPSEEK_API_KEY\" not in os.environ:\n",
    "    os.environ[\"DEEPSEEK_API_KEY\"] = input(\"Enter your Deepseek API Key: \").strip()\n",
    "\n",
    "def load_sentences_from_docx(doc_path: str) -> List[str]:\n",
    "    \"\"\"Load sentences from a Word document\"\"\"\n",
    "    doc = docx.Document(doc_path)\n",
    "    sentences = [para.text.strip() for para in doc.paragraphs if para.text.strip()]\n",
    "    return sentences\n",
    "\n",
    "def batch_process_sentences(sentences: List[str], batch_size: int = 10) -> List[str]:\n",
    "    \"\"\"Process sentences in batches, each time processing batch_size sentences\"\"\"\n",
    "    processed_sentences = []\n",
    "    \n",
    "    # Change 2: Deepseek client configuration\n",
    "    client = openai.OpenAI(\n",
    "        api_key=os.environ[\"DEEPSEEK_API_KEY\"],\n",
    "        base_url=\"https://api.deepseek.com/v1\"  # Deepseek API endpoint\n",
    "    )\n",
    "\n",
    "    # Process in batches\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        print(f\"ðŸ“¦ Processing batch {i//batch_size + 1} ({i+1} to {min(i+batch_size, len(sentences))})\")\n",
    "        \n",
    "        # Create prompt for each batch\n",
    "        batch_prompt = create_batch_prompt(batch)\n",
    "        \n",
    "        try:\n",
    "            # Change 3: Increase max_tokens and handle batch processing\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"deepseek-chat\", \n",
    "                messages=[{\"role\": \"user\", \"content\": batch_prompt}],\n",
    "                temperature=0.2,\n",
    "                max_tokens=4096,  # Increase token limit to fit more content\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            gpt_output = response.choices[0].message.content.strip()\n",
    "            \n",
    "            if not gpt_output:\n",
    "                print(f\"âš ï¸ API returned empty response, skipping this batch\")\n",
    "                continue\n",
    "                \n",
    "            # Parse batch results\n",
    "            try:\n",
    "                results = json.loads(gpt_output)\n",
    "                if \"results\" in results:\n",
    "                    for result in results[\"results\"]:\n",
    "                        if result.get(\"is_kg_worthy\"):\n",
    "                            refined_sentence = result.get(\"refined_sentence\") or result.get(\"original_sentence\")\n",
    "                            if refined_sentence:\n",
    "                                processed_sentences.append(refined_sentence)\n",
    "                                print(f\"âœ… Refined: {refined_sentence}\")\n",
    "                        else:\n",
    "                            print(f\"âŒ Discarded: {result.get('original_sentence', 'Unknown sentence')}\")\n",
    "                else:\n",
    "                    print(f\"âš ï¸ Returned format does not match expectation: {gpt_output[:100]}...\")\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"âš ï¸ JSON parsing error: {e}\\nReturned content:\\n{gpt_output[:200]}...\")\n",
    "                \n",
    "            # Short delay after each batch to avoid API rate limits\n",
    "            time.sleep(1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Batch processing failed: {str(e)}\")\n",
    "            time.sleep(3)  # Wait longer after error\n",
    "            \n",
    "    return processed_sentences\n",
    "\n",
    "def create_batch_prompt(sentences: List[str]) -> str:\n",
    "    \"\"\"Create a prompt for one batch of sentences\"\"\"\n",
    "    sentences_json = json.dumps(sentences, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are an advanced AI assistant trained for academic research.\n",
    "    Your task is to evaluate and refine multiple research sentences for use in a **Knowledge Graph (KG)** related to **Ultra-High Performance Concrete (UHPC)**.\n",
    "\n",
    "    ---\n",
    "    **ðŸ“Œ Task 1: Sentence Judgment**\n",
    "    1ï¸âƒ£ **KEEP** sentences that contain **scientific knowledge that directly contributes to KG construction**, such as:\n",
    "       - Numerical data (e.g., \"UHPC has a compressive strength of 150 MPa\").\n",
    "       - Clear relationships between UHPC components, properties, and effects.\n",
    "       - Experimental findings, performance results, or material compositions.\n",
    "       - Key processing techniques and their effects on UHPC.\n",
    "    2ï¸âƒ£ **REMOVE** sentences that:\n",
    "       - Are too vague or generic (e.g., \"Concrete is widely used in construction\").\n",
    "       - Require extra context to be useful.\n",
    "       - Reference figures, tables, or sections without details.\n",
    "       - Lack clear meaning for KG.\n",
    "\n",
    "    ---\n",
    "    **ðŸ“Œ Task 2: Sentence Optimization**\n",
    "    - If a sentence is useful, **refine it to improve clarity, precision, and academic quality**.\n",
    "    - **Do NOT change the scientific meaning** or introduce unverified data.\n",
    "    - Ensure each sentence is **grammatically correct, concise, and formal**.\n",
    "\n",
    "    ---\n",
    "    **Input Sentences (JSON Array):**\n",
    "    {sentences_json}\n",
    "\n",
    "    ---\n",
    "    **âœ… Output Format (Strict JSON Only):**\n",
    "    Return a JSON object with a \"results\" array containing an object for each input sentence:\n",
    "    ```json\n",
    "    {{\n",
    "        \"results\": [\n",
    "            {{\n",
    "                \"original_sentence\": \"First sentence\",\n",
    "                \"is_kg_worthy\": true or false,\n",
    "                \"refined_sentence\": \"Refined first sentence or null if not worthy\"\n",
    "            }},\n",
    "            {{\n",
    "                \"original_sentence\": \"Second sentence\",\n",
    "                \"is_kg_worthy\": true or false,\n",
    "                \"refined_sentence\": \"Refined second sentence or null if not worthy\"\n",
    "            }},\n",
    "            ... and so on for each input sentence\n",
    "        ]\n",
    "    }}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def save_sentences_to_doc(sentences: List[str], doc_path: str) -> None:\n",
    "    \"\"\"Save processed sentences into a Word document\"\"\"\n",
    "    doc = Document()\n",
    "    doc.add_heading(\"Step3_Text_Judgment_Result_2\", level=1)\n",
    "    for i, sentence in enumerate(sentences, 1):\n",
    "        doc.add_paragraph(f\"{i}. {sentence}\")\n",
    "    doc.save(doc_path)\n",
    "    print(f\"âœ… Saved file at: {doc_path}\")\n",
    "\n",
    "def main(input_doc_path: str, output_doc_path: str, batch_size: int = 10) -> None:\n",
    "    \"\"\"Main function to run the entire process\"\"\"\n",
    "    print(\"ðŸ“‚ Reading input file...\")\n",
    "    sentences = load_sentences_from_docx(input_doc_path)\n",
    "    print(f\"ðŸ“œ Number of original sentences: {len(sentences)}\")\n",
    "\n",
    "    print(f\"ðŸ¤– Deepseek batch processing (batch size = {batch_size})...\")\n",
    "    processed_sentences = batch_process_sentences(sentences, batch_size)\n",
    "    print(f\"âœ¨ Number of valid sentences: {len(processed_sentences)}\")\n",
    "\n",
    "    print(\"ðŸ“‘ Saving results...\")\n",
    "    save_sentences_to_doc(processed_sentences, output_doc_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_doc = r\"D:\\SIT\\knowledge\\Result\\step2_Text_Judgment_Result.docx\"\n",
    "    output_doc = r\"D:\\SIT\\knowledge\\Result\\step3_Text_Judgment_Result_2.docx\"\n",
    "    batch_size = 10  # Can be adjusted if needed\n",
    "    main(input_doc, output_doc, batch_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
